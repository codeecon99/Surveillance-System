{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e43f63d-bc7e-4bb0-90f2-e5845ee14767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put together each unit to create a complete pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0e26e75-983f-4ee0-9e36-37f109d137fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "import tempfile\n",
    "import cv2\n",
    "import subprocess\n",
    "import re\n",
    "import numpy as np\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from datetime import datetime, timedelta\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75ab19f2-0a4d-4dca-8f1f-03f8e8676988",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\jacob/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2024-6-8 Python-3.12.3 torch-2.3.0 CUDA:0 (NVIDIA GeForce RTX 3070, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# Load the YOLOv5 model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "#model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3257135-2884-4bc4-ae54-54cf7aefa095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_alpr(image_data):\n",
    "    try:\n",
    "        # Create a temporary file to store the image data\n",
    "        with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as temp_img_file:\n",
    "            temp_img_file.write(image_data)\n",
    "            temp_img_path = temp_img_file.name\n",
    "        \n",
    "        command = [\n",
    "            'alpr',\n",
    "            '-c', 'us',\n",
    "            '--topn', '1',\n",
    "            temp_img_path  # Use the temporary file path here\n",
    "        ]\n",
    "        \n",
    "        result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
    "        return result.stdout\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error running alpr: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        try:\n",
    "            # Remove the temporary file after use\n",
    "            if temp_img_path:\n",
    "                os.remove(temp_img_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error cleaning up temp file: {e}\")\n",
    "\n",
    "def process_image(image_path):\n",
    "    #print(f\"Processing image: {image_path}\")\n",
    "    alpr_output = run_alpr(image_path)\n",
    "    if alpr_output:\n",
    "        #print(\"ALPR Output:\")\n",
    "        return alpr_output\n",
    "    else:\n",
    "        print(\"No output from ALPR.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a16006e-b213-4572-a2b9-a1c32a382f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_as_bytes(image):\n",
    "    if image is None:\n",
    "        # Create a blank image with a specified size and color (e.g., white)\n",
    "        blank_image = Image.new('RGB', (100, 100), color = 'white')\n",
    "        image = blank_image\n",
    "\n",
    "    with io.BytesIO() as output:\n",
    "        image.save(output, format='JPEG')  # Adjust format as needed ('JPEG', 'PNG', etc.)\n",
    "        image_bytes = output.getvalue()\n",
    "    return image_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "368e66fd-e1c7-47aa-804d-b3a253c6fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Yolov5_Detection(img):\n",
    "\n",
    "    results = model(img) #Full image\n",
    "\n",
    "    #Makes more sense: Dont want to be passing in location of image each time rather just the image!\n",
    "    if not isinstance(img, Image.Image):\n",
    "        img = Image.fromarray(img)  # Assuming img is a numpy array or similar format\n",
    "\n",
    "    #if isinstance(img, Image.Image):\n",
    "        #img = Image.open(img) #Or error\n",
    "\n",
    "    # Initialize variables\n",
    "    cropped_image = None\n",
    "    confidence = None\n",
    "    label = None\n",
    "\n",
    "    boxes = results.xyxy[0]  # Get the bounding box coordinates for the image\n",
    "    for result in boxes: \n",
    "\n",
    "        x1, y1, x2, y2, conf, cls = result  # Bounding box coordinates, confidence, and class index\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "        bounding_box_cs = [x1, y1, x2, y2] #NEW\n",
    "    \n",
    "        label = results.names[int(cls)]  # Get the class name using the class index\n",
    "        confidence = conf.item() #Get confidence\n",
    "        cropped_image = img.crop((x1, y1, x2, y2)) #get cropped image\n",
    "        \n",
    "    return  results, cropped_image, confidence, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5d9c1b4-39aa-429d-bbee-db0d6468249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path):\n",
    "    # List to store frames\n",
    "    frames = []\n",
    "    \n",
    "    # Load the video\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    success, frame = video.read()\n",
    "\n",
    "    # Read until the end of the video\n",
    "    while success:\n",
    "        # Append the frame to the list\n",
    "        frames.append(frame)\n",
    "        # Read the next frame\n",
    "        success, frame = video.read()\n",
    "    \n",
    "    # Release the video object\n",
    "    video.release()\n",
    "\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42f2502d-701a-4c1e-ba92-6db8d7bcdc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Driver(feed): #\n",
    "    #feed = 'C:\\\\Users\\\\jacob\\\\Desktop\\\\Projects\\\\ANPR_Camera\\\\TEST_PHOTOS\\\\TEST1.jpg'\n",
    "    #feed = Image\n",
    "    yolo_det = Yolov5_Detection(feed) #Takes a frame from feed\n",
    "\n",
    "    cropped_image = yolo_det[1] #Only grab the inner bounding box\n",
    "\n",
    "    #OpenALPR to read license plate\n",
    "    OpenALPR = process_image(read_image_as_bytes(cropped_image))\n",
    "    #OpenALPR = extract_plate_info(OpenALPR) #Create this function later and ensure it matches all possible outputs\n",
    "\n",
    "    return yolo_det, OpenALPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23db80cf-4c79-48c3-9418-96b25e66fd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpr_detection(feed):\n",
    "    OpenALPR = process_image(read_image_as_bytes(cropped_image))\n",
    "    return OpenALPR\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "392820f7-9a15-4c17-8e7e-6e6217a140d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_plate_info(output_str):\n",
    "    if \"No license plates found.\" in output_str:\n",
    "        return [\"\", 0.0]\n",
    "    \n",
    "    # Split the output string by lines\n",
    "    lines = output_str.strip().split('\\n')\n",
    "    \n",
    "    # Extract the license plate and confidence from the first line\n",
    "    plate_info_line = lines[1].strip()\n",
    "    \n",
    "    # Extract plate number and confidence\n",
    "    plate_number = plate_info_line.split('- ')[-1].split('\\t')[0].strip()\n",
    "    confidence_str = plate_info_line.split('confidence: ')[-1].strip()\n",
    "    confidence = float(confidence_str[:-1])  # Remove the trailing '\\n' and convert to float\n",
    "    \n",
    "    return [plate_number, round(confidence, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87881b5c-f0be-4855-9c6f-67787e16dbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_license_plate(lst):\n",
    "    # Extract the license plates (first element) from each inner list, excluding empty strings\n",
    "    license_plates = [sublist[0] for sublist in lst if sublist[0]]\n",
    "    \n",
    "    # Count occurrences of each license plate\n",
    "    counts = Counter(license_plates)\n",
    "    \n",
    "    # Get the most common license plate and its count\n",
    "    most_common = counts.most_common(1)\n",
    "    \n",
    "    # Check if there is at least one non-empty license plate\n",
    "    if most_common:\n",
    "        most_common_license_plate = most_common[0][0]\n",
    "    else:\n",
    "        most_common_license_plate = None  # or you can handle it differently if needed\n",
    "    \n",
    "    return most_common_license_plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "632f15fd-bc67-4a0c-8a64-40ee66260aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolov5_results_to_numpy(results):\n",
    "    # Show the results using Matplotlib\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax.imshow(np.squeeze(results.render()[0]))\n",
    "    ax.axis('off')  # Hide axes\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Convert the Matplotlib figure to a NumPy array\n",
    "    fig.canvas.draw()\n",
    "    image_np = np.array(fig.canvas.renderer._renderer)\n",
    "    plt.close(fig)  # Close the Matplotlib figure to free memory\n",
    "\n",
    "    return image_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e10bd0a1-13d2-4e1d-8d56-9e84c5b85d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_numpy_image(image_np):\n",
    "    # Convert NumPy array to PIL Image\n",
    "    image_pil = Image.fromarray(image_np)\n",
    "\n",
    "    # Display the PIL Image in Jupyter Notebook\n",
    "    display(image_pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fee61e80-657f-4e42-8eec-18fa2474bc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video(images, output_video_path, fps=24):\n",
    "    # Determine the shape of the images (assuming all have the same shape)\n",
    "    height, width, _ = images[0].shape\n",
    "\n",
    "    # Initialize VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for MP4 format\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    # Write each frame to the video\n",
    "    for image in images:\n",
    "        # Convert RGB to BGR (OpenCV uses BGR)\n",
    "        frame_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        out.write(frame_bgr)\n",
    "\n",
    "    # Release the VideoWriter and close all OpenCV windows\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "167e6a55-9e89-47c4-97b7-6ef7ad45b7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_timestamps(video_path, start_time=None):\n",
    "    # Load the video file\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get the frame rate of the video\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # If start_time is not provided, use the current datetime\n",
    "    if start_time is None:\n",
    "        start_time = datetime.now()\n",
    "\n",
    "    timestamps = []\n",
    "\n",
    "    # Loop through the video frames\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Get the current frame number\n",
    "        frame_number = int(video.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "        \n",
    "        # Calculate the timestamp (date and time) for the current frame\n",
    "        timestamp = start_time + timedelta(seconds=(frame_number / fps))\n",
    "\n",
    "        # Store the timestamp (and optionally the frame)\n",
    "        timestamps.append((frame_number, timestamp))\n",
    "\n",
    "        # Optionally: Process the frame here or save it\n",
    "        # e.g., cv2.imwrite(f'frame_{frame_number}.jpg', frame)\n",
    "\n",
    "    video.release()\n",
    "    return timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6de073c1-8caa-4b24-bc4f-df36432e0d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_same(lst):\n",
    "    \"\"\"\n",
    "    Checks if the first 5 elements of the list are the same.\n",
    "    \n",
    "    Parameters:\n",
    "    - lst: A list of numbers.\n",
    "    \n",
    "    Returns:\n",
    "    - The first element if the first 5 elements are the same, otherwise 0.\n",
    "    \"\"\"\n",
    "    if len(lst) < 5:\n",
    "        return 0  # Not enough elements to check\n",
    "\n",
    "    first_five = lst[:5]\n",
    "    \n",
    "    # Check if all first 5 elements are the same\n",
    "    if len(set(first_five)) == 1:\n",
    "        return first_five[0]\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27230d5a-7d9a-45da-9817-409c02d8fd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeler(number):\n",
    "    if number == 1:\n",
    "        return 'car'\n",
    "    elif number == 2:\n",
    "        return 'person'\n",
    "    else:\n",
    "        return 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50ad832a-26c9-4105-976a-ee9332581b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blob_data_lp(det_lst):\n",
    "\n",
    "    if det_lst[0] == 'car':\n",
    "        lp_field = read_lp(det_lst)\n",
    "        \n",
    "    else:\n",
    "       lp_field = 'none'\n",
    "\n",
    "    return lp_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50587562-9bae-421e-b945-8127b716d0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_det(det):\n",
    "    complete_vid = []\n",
    "    for i in range(len(det)):\n",
    "        complete_vid.append(yolov5_results_to_numpy(det[i][2][0]))\n",
    "    return complete_vid  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48fdf7cc-8e11-4524-96c1-5f1419c0e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lp(det_blob):\n",
    "\n",
    "    det_slice_test = det_blob[1]\n",
    "\n",
    "    #run license plates for the car instance\n",
    "    car_det_lp = []\n",
    "    for i in range(len(det_slice_test)):\n",
    "        cropped_image = det_slice_test[i][2][1] #Only grab the inner bounding box\n",
    "        \n",
    "        #OpenALPR to read license plate\n",
    "        OpenALPR = extract_plate_info(process_image(read_image_as_bytes(cropped_image)))\n",
    "    \n",
    "        car_det_lp.append(OpenALPR)\n",
    "        #print(OpenALPR)\n",
    "    \n",
    "    #add licence plate to all car detections\n",
    "    car_det_lp_final = most_common_license_plate(car_det_lp)\n",
    "\n",
    "    return car_det_lp_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43312dd-86b1-420b-93f0-98a037eefb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListSplitter:\n",
    "    def __init__(self):\n",
    "        self.current_chunk = []\n",
    "        self.ones_streak = 0\n",
    "        self.zeros_streak = 0\n",
    "        self.twos_streak = 0\n",
    "        self.inside_chunk = False\n",
    "        self.result = []\n",
    "\n",
    "    def process_element(self, element):\n",
    "        self.current_chunk.append(element)\n",
    "\n",
    "        # Check for streaks of 1s, 2s, or 0s\n",
    "        if element == 1:\n",
    "            self.ones_streak += 1\n",
    "            self.zeros_streak = 0\n",
    "            self.twos_streak = 0\n",
    "        elif element == 2:\n",
    "            self.twos_streak += 1\n",
    "            self.ones_streak = 0\n",
    "            self.zeros_streak = 0\n",
    "        elif element == 0:\n",
    "            self.zeros_streak += 1\n",
    "            self.ones_streak = 0\n",
    "            self.twos_streak = 0\n",
    "\n",
    "        # Start a chunk when we have a streak of 5 ones or twos\n",
    "        if (self.ones_streak == 5 or self.twos_streak == 5) and not self.inside_chunk:\n",
    "            self.inside_chunk = True\n",
    "\n",
    "        # Split the chunk only when we have 5 consecutive zeros\n",
    "        if self.zeros_streak == 5 and self.inside_chunk:\n",
    "            completed_chunk = self.current_chunk[:-5]\n",
    "            self.result.append(completed_chunk)\n",
    "            self.current_chunk = self.current_chunk[-5:]\n",
    "            self.inside_chunk = False\n",
    "            return completed_chunk\n",
    "\n",
    "        # End a chunk when we have a streak of 5 ones or 5 twos\n",
    "        if (self.ones_streak == 5 or self.twos_streak == 5) and self.inside_chunk:\n",
    "            completed_chunk = self.current_chunk[:-5]\n",
    "            self.result.append(completed_chunk)\n",
    "            self.current_chunk = self.current_chunk[-5:]\n",
    "            self.inside_chunk = True\n",
    "            return completed_chunk\n",
    "\n",
    "        return None  # No chunk completed yet\n",
    "\n",
    "    def finalize(self):\n",
    "        if self.current_chunk:\n",
    "            self.result.append(self.current_chunk)\n",
    "            return self.current_chunk\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba8751c-fdfa-4336-b4bc-0af85fbc0ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Azure_Push(blob):\n",
    "    \n",
    "    object = blob[0]\n",
    "    min_frame = blob[1][0][0]\n",
    "    max_frame= blob[1][-1][0]\n",
    "    min_ts = blob[1][0][1]\n",
    "    max_ts= blob[1][-1][1]\n",
    "    license_plate = blob_data_lp(blob)\n",
    "    \n",
    "    #create video and save to a location for now\n",
    "    det = blob[1]\n",
    "    image_list = video_det(det)\n",
    "    output_video_path = 'C:\\\\Users\\\\jacob\\\\Desktop\\\\Projects\\\\ANPR_Camera\\\\FINAL_PROJECT\\\\Data\\\\Temporary_Video.mp4'\n",
    "    create_video(image_list, output_video_path)\n",
    "    \n",
    "    data_output = [object,min_frame,max_frame,min_ts,max_ts,license_plate,output_video_path]\n",
    "\n",
    "    # Load environment variables from .env file\n",
    "    load_dotenv(dotenv_path='C:\\\\Users\\\\jacob\\\\Desktop\\\\Projects\\\\ANPR_Camera\\\\FINAL_PROJECT\\\\Azure_Credentials.env')\n",
    "    \n",
    "    # Fetch connection string and container name from environment variables\n",
    "    connection_string = os.getenv('AZURE_CONNECTION_STRING')\n",
    "    container_name = os.getenv('AZURE_CONTAINER_NAME')\n",
    "    \n",
    "    # BlobServiceClient instance\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    \n",
    "    # Sample data\n",
    "    #detection_results = data_output\n",
    "    \n",
    "    # Metadata for the blob\n",
    "    metadata = {\n",
    "        'object_detected': data_output[0],\n",
    "        'start_frame': str(data_output[1]),\n",
    "        'end_frame': str(data_output[2]),\n",
    "        'start_time': data_output[3],\n",
    "        'end_time': data_output[4],\n",
    "        'license_plate': data_output[5],\n",
    "    }\n",
    "    \n",
    "    # Video path and blob name\n",
    "    video_path = data_output[6]\n",
    "    \n",
    "    # Create a dynamic video name using license plate and timestamps\n",
    "    obj_det = data_output[0]\n",
    "    start_time = data_output[3].replace(\":\", \"-\").replace(\".\", \"-\")\n",
    "    end_time = data_output[4].replace(\":\", \"-\").replace(\".\", \"-\")\n",
    "    video_name = f\"{obj_det}_{start_time}_to_{end_time}.mp4\"\n",
    "    \n",
    "    \n",
    "    # Upload video file with metadata\n",
    "    blob_client = container_client.get_blob_client(video_name)\n",
    "    \n",
    "    with open(video_path, \"rb\") as video_file:\n",
    "        blob_client.upload_blob(video_file, metadata=metadata, overwrite=True)\n",
    "    #print(f\"Video with metadata uploaded as {video_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1e1999a-fc39-4408-8517-9c63399011e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"C:\\\\Users\\\\jacob\\\\Desktop\\\\Projects\\\\ANPR_Camera\\\\Data\\\\DSCN1162.mp4\"\n",
    "frames = extract_frames(video_path)\n",
    "timestamps = get_video_timestamps(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82904110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_engine():\n",
    "\n",
    "    splitter = ListSplitter()\n",
    "    combined_data = []\n",
    "    data = []\n",
    "    input_list  = frames\n",
    "    check_lst = [['none', []]]\n",
    "    len_count = []\n",
    "    test_lst_V2 = []\n",
    "    new_counter = 0\n",
    "    index_count = 0\n",
    "    count = 0\n",
    "    len_check_lst = 0\n",
    "    start_index = 0\n",
    "    #yolo_det = []\n",
    "    detection_data_frame = []\n",
    "    test_final = []\n",
    "    \n",
    "    \n",
    "    #Testing functionality delete later\n",
    "    det_slice_totals = []\n",
    "    \n",
    "    for elem in input_list:\n",
    "    \n",
    "        yolo = Yolov5_Detection(elem)\n",
    "        #yolo_det.append(yolo)\n",
    "        object = yolo[3]\n",
    "    \n",
    "        frame_number, timestamp = timestamps[count]\n",
    "        detection_data = [frame_number,timestamp.strftime('%Y-%m-%d %H:%M:%S.%f'),yolo]\n",
    "        detection_data_frame.append(detection_data)\n",
    "        count = count + 1\n",
    "    \n",
    "        if object == 'car':\n",
    "            object_num = 1\n",
    "        elif object == 'person':\n",
    "            object_num = 2\n",
    "        else:\n",
    "            object_num = 0\n",
    "    \n",
    "        result = splitter.process_element(object_num)\n",
    "        if result is not None:\n",
    "            chunk = result\n",
    "            label = labeler(check_same(result))\n",
    "            \n",
    "            if chunk:\n",
    "                 combined_data.append([label,chunk])\n",
    "                 if combined_data[index_count][0] == check_lst[-1][0]:\n",
    "                    # Extend the previous list with the current list\n",
    "                     check_lst[-1][1].extend(combined_data[index_count][1]) ##If it extends the list need to remove the previous version until we move onto                                                             #a new element! make a same counter set to 0 once its free and push into the final list!  \n",
    "                 else:\n",
    "                    # If different, add the current element to the result list\n",
    "                     check_lst.append(combined_data[index_count])\n",
    "                 test_lst_V2.append(check_lst[-1])\n",
    "                 len_check_lst = len(check_lst)\n",
    "                 len_count.append(len_check_lst)\n",
    "                 if len_count[index_count] > len_count[index_count - 1]:\n",
    "                    #print(test_lst_V2[index_count-1])#Send to Azure!!!!\n",
    "                    #print(len(test_lst_V2[index_count-1][1]))#len test\n",
    "                     \n",
    "                    #Get object here\n",
    "                    obj_res = test_lst_V2[index_count-1][0]\n",
    "    \n",
    "                    #Index functionallity \n",
    "                    length = len(test_lst_V2[index_count-1][1])\n",
    "                    end_index = start_index + length\n",
    "    \n",
    "                    #Indexing detection data\n",
    "                    det_slice = [obj_res, detection_data_frame[start_index:end_index]]\n",
    "                    Azure_Push(det_slice)\n",
    "                    start_index = end_index      \n",
    "                \n",
    "                 index_count = index_count + 1\n",
    "            \n",
    "    current_end_lst = check_lst[-1]   \n",
    "    check_lst_2 = check_lst[-1][0]\n",
    "         \n",
    "    # Finalize to get the last chunk\n",
    "    final_chunk = splitter.finalize()\n",
    "    if final_chunk is not None:\n",
    "        chunk = final_chunk\n",
    "        label = labeler(check_same(final_chunk))\n",
    "        combined_data.append([label,chunk])\n",
    "        if combined_data[-1][0] == check_lst_2:\n",
    "            # Extend the previous list with the current list\n",
    "            check_lst[-1][1].extend(combined_data[index_count][1])\n",
    "            #print(check_lst[-1])#send to Azure!\n",
    "            #print(len(check_lst[-1][1]))#len test\n",
    "            \n",
    "            #Get object here\n",
    "            obj_res = check_lst[-1][0]\n",
    "    \n",
    "            #Testing index functionallity \n",
    "            length = len(check_lst[-1][1])\n",
    "            end_index = start_index + length\n",
    "            det_slice = [obj_res, detection_data_frame[start_index:end_index]]\n",
    "            Azure_Push(det_slice)\n",
    "            #print(det_slice)\n",
    "            #det_slice_totals.append(det_slice)\n",
    "            start_index = end_index\n",
    "            \n",
    "    \n",
    "        \n",
    "        else:\n",
    "            # If different, add the current element to the result list\n",
    "            #print(current_end_lst) #Send to Azure!\n",
    "            #print(len(current_end_lst[1]))#len test\n",
    "    \n",
    "            #Get object here\n",
    "            obj_res = current_end_lst[0]\n",
    "    \n",
    "            #Testing index functionallity \n",
    "            length = len(current_end_lst[1])\n",
    "            end_index = start_index + length\n",
    "            det_slice = [obj_res, detection_data_frame[start_index:end_index]]\n",
    "            #print(det_slice)\n",
    "            Azure_Push(det_slice)\n",
    "            #det_slice_totals.append(det_slice) #remove for production\n",
    "            start_index = end_index\n",
    "    \n",
    "            check_lst.append(combined_data[index_count])\n",
    "            #print(check_lst[-1]) #Send to Azure!\n",
    "            #print(len(check_lst[-1][1]))#len test\n",
    "            \n",
    "            #Get object here\n",
    "            obj_res = check_lst[-1][0]\n",
    "    \n",
    "            #Testing index functionallity \n",
    "            length = len(check_lst[-1][1])\n",
    "            end_index = start_index + length\n",
    "            det_slice = [obj_res, detection_data_frame[start_index:end_index]]\n",
    "            #print(det_slice)\n",
    "            Azure_Push(det_slice)\n",
    "            #det_slice_totals.append(det_slice)\n",
    "            start_index = end_index\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a49ea97-aab6-4c79-977d-cc9994788251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will run the engine where a video feed is pushing detections to Azure\n",
    "#detection_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275004d8-0e64-4416-89ca-b05a47a2337a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf05ba8-ad59-484f-ba51-db700cb825d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d7c41c-4763-4ece-b0d4-4d4f57791483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b3dc97-8e4b-42b4-a39c-6378557f4cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc4c05e-6170-4920-9279-6f8e39bd1513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9db8041-ceb3-4f16-8608-de417fef02fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e39b166-1282-4467-8fa0-5373225dc46b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d9d145-df50-416b-9d0f-2d315cd1cd74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cb5b54-3a0f-40b0-86c7-ca83707fd1ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea279b8c-22fb-4407-9dc2-acbc041874ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be4c53e-95d7-4329-ae5c-eaa040d66623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9c14a1-08ab-4c02-936a-96d52d17fa49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0acba0-101e-4183-9d9b-60b49772000e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5791f1c-426a-4294-9bce-e7570f51a04e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ff4ae0-69a2-4960-a743-9e568da2e949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5873e2f2-3f17-4f57-969e-b063acd04e45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c35339-8638-4f6e-b09d-d00079e2d8a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f4dcec-369a-4a9b-94a3-e688ba50dbfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c8bc7b-4a8b-427e-bfe0-46205ff4d10f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8ed045-2127-4972-9c19-be5ac38cbd5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477f21cf-b4c2-4339-9316-1c3893fdcb3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad03e61b-1731-478f-8a27-92ce54b02272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48600d1b-ac4e-4077-b156-df5766407293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dc4026-b14f-4aa2-b423-ba5de79687fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd005df9-e587-4a2f-b545-6de0ae221cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17310c31-73d4-40c3-bcb6-8c18443ec0e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917ab061-9c10-4d91-b955-c2eab81927d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd5262f-bba0-42ab-b407-a578f3302fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21d80b2-6e2a-4ff4-9ec8-dc6979a8ecbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff156b24-5e85-4ccf-b928-f7030c6cd5ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe3d1d9-2ab5-408a-8a07-471671e52eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f6bdb8-9ec7-4afe-995e-1a06c4fcc476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c1b829-ea96-4d9c-af0d-b926850cf614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764b4908-09df-460a-b250-c187d7aa409e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96732935-38d1-47ca-a213-529a8cbc2949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf51d03f-57e3-44b3-a907-00ba2ca9abbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40740cc8-b08e-4a75-8978-b24f322b0b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428299f3-62e9-4eee-a09a-8423fc2a97f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603b3e19-a891-4c4a-92a2-c5dc12444042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfa7cf2-0607-4333-b112-d9914267aafc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d6f5cc-ee24-4b35-af83-de6a5bc8f18a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c0dcf7-9528-42dd-b899-6ce9e9d153b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4131c93b-4dd5-4df4-8079-b7e1c8bd893a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43ec924-26da-40ab-b0c1-9c175212a6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426a4cd7-9709-43d8-b38c-ec8362cc789a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cde5d71-0ce1-406f-85cb-8408696cc4a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7731c576-81f9-4a10-b508-9cb68cca741d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffc108b-4cb1-4e27-a097-9ca57bbd9f95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6016353-bc05-4605-aee8-c34121d76616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3af0d0-8168-4a6c-8787-29a987fbb70d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac299f04-eba7-4c4c-af58-b9dfbbfde1be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac49ab8-c128-4bce-803f-3345977c0989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40117657-1d39-457d-b9a2-6f3878798ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6205c43f-ada5-4db9-964e-9de69cb347a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5fee97-29e8-4042-93ba-6f1776dc1f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f42318-942f-4f4b-8e4d-01afbac97072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8bcbf1-6da0-4c79-b337-2d75adccec44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d90698-a0cd-48e9-ad9b-4b46ffd867c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b345db02-61ae-4783-ba99-ee078103424a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a4698d-04c6-40a5-915f-f03e3778aba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27602013-bf24-4749-8923-771933fffdb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f87cf5-ea16-4da0-ae2e-6f36d649177f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7d2472-4d4b-4e30-985c-a2a9e48f5a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581960a7-7853-4ebb-9818-eeaf4b63112d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2816923-4866-4a24-add9-e9a76a6a6fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3d0dbe-8559-47fb-a573-d7ce92b1545a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b930b9-09c2-4ac1-b493-4539079f3ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2019702c-3416-4b64-80c5-cc6ccfeaf52e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb63f75-4f34-4d40-bd32-312b9c6f9c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b881fe02-127d-49ad-88f0-6c51ebb0266f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5180e6cb-2720-46b7-b7c0-dde48854cadf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b5810f-6c11-433c-aa49-fbdb46594b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c038f724-689f-414c-8f24-0efd5818857f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcd51cf-bf82-4b25-ad75-2d00088c4b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dada7dea-bffc-43b4-901b-96ffb46b3b60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c5b820-8f32-4a9a-8d5e-751450e109ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78465d01-594d-49e1-b3d9-a5a1ac5d352e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b02556-8225-4e14-a295-27822ac8f931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed783a6-a639-4985-97dd-8b762f09bec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587a93c1-47e8-40ba-9d20-da64623f7266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
